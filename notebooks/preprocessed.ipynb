{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af7830e-0e64-4bfc-bf2e-5bff69b15c7e",
   "metadata": {},
   "source": [
    "# Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d4d7c2a-8bc1-4c41-8893-13ca0dda33a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/d5x0r6t10l52bms12sy70rzc0000gn/T/ipykernel_3025/4232228962.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv('/Users/marina/Desktop/final_project/data/cleaned/okcupid_cleaned.csv')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "df1 = pd.read_csv('/Users/marina/Desktop/final_project/data/cleaned/okcupid_cleaned.csv')\n",
    "#data/raw/okcupid_profiles .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb3784d2-33c0-4226-88c2-2d8c549dc177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59944 entries, 0 to 59943\n",
      "Data columns (total 33 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   age          59944 non-null  int64 \n",
      " 1   status       59944 non-null  object\n",
      " 2   sex          59944 non-null  object\n",
      " 3   orientation  59944 non-null  object\n",
      " 4   body_type    59944 non-null  object\n",
      " 5   diet         59944 non-null  object\n",
      " 6   drinks       59944 non-null  object\n",
      " 7   drugs        59944 non-null  object\n",
      " 8   education    59944 non-null  object\n",
      " 9   ethnicity    59944 non-null  object\n",
      " 10  height       59944 non-null  object\n",
      " 11  income       59944 non-null  int64 \n",
      " 12  job          59944 non-null  object\n",
      " 13  last_online  59944 non-null  object\n",
      " 14  location     59944 non-null  object\n",
      " 15  offspring    59944 non-null  object\n",
      " 16  pets         59944 non-null  object\n",
      " 17  religion     59944 non-null  object\n",
      " 18  sign         59944 non-null  object\n",
      " 19  smokes       59944 non-null  object\n",
      " 20  speaks       59944 non-null  object\n",
      " 21  essay0       59944 non-null  object\n",
      " 22  essay1       59944 non-null  object\n",
      " 23  essay2       59944 non-null  object\n",
      " 24  essay3       59944 non-null  object\n",
      " 25  essay4       59944 non-null  object\n",
      " 26  essay5       59944 non-null  object\n",
      " 27  essay6       59944 non-null  object\n",
      " 28  essay7       59944 non-null  object\n",
      " 29  essay8       59944 non-null  object\n",
      " 30  essay9       59944 non-null  object\n",
      " 31  city         59944 non-null  object\n",
      " 32  state        59944 non-null  object\n",
      "dtypes: int64(2), object(31)\n",
      "memory usage: 15.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/hectoroik/date-a-scientist-classification-models-python\n",
    "#https://www.kaggle.com/datasets/andrewmvd/okcupid-profiles/code\n",
    "#https://www.canva.com/p/templates/EAF2kSos8SE-presentaci-n-de-infograf-as-esquemas-marketing-profesional-colores-pasteles/\n",
    "#https://www.canva.com/p/templates/EAFtldFLwVY-presentaci-n-proyecto-trabajo-creativa-profesional-azul/\n",
    "#https://www.canva.com/p/templates/EAFC0JtURT0-presentacion-moda-aesthetic-minimalist-rosa/\n",
    "#https://www.canva.com/es_es/plantillas/EAEp_rpQXkw-presentacion-de-educacion-proyecto-de-grupo-animado-abstracto-estampado-morado-y-verde/\n",
    "#https://www.canva.com/p/templates/EAFtldFLwVY-presentaci-n-proyecto-trabajo-creativa-profesional-azul/\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c6829-9f9a-42c5-9099-c857f8ac3e2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a65bed5-045c-4e0b-80ce-50d743646ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['m', 'f'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9362204-4632-46b2-8fb2-85a0fe866ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each sex:\n",
      "sex\n",
      "m    60.0\n",
      "f    40.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    SEX STATISTICS\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'sex' column\n",
    "sex_counts = df1['sex'].value_counts()\n",
    "\n",
    "# percentage of each value\n",
    "sex_percentage= round((sex_counts / len(df1)) * 100,0)\n",
    "\n",
    "print(\"Percentage of each sex:\")\n",
    "print(sex_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c60a2172-df83-4bad-8410-c919b9836a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for income grouped by gender:\n",
      "       count           mean            std      min      25%       50%  \\\n",
      "sex                                                                      \n",
      "f    24116.0  110233.497595   78302.272293  20000.0  81583.0   99588.0   \n",
      "m    35828.0  115062.970219  104446.830932  20000.0  81583.0  101478.0   \n",
      "\n",
      "          75%        max  \n",
      "sex                       \n",
      "f    129155.0  1000000.0  \n",
      "m    122712.0  1000000.0  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    INCOME STATISTICS BY GENDER\n",
    "'''\n",
    "\n",
    "# Group by gender and calculate statistics for income\n",
    "income_stats_gender = df1.groupby('sex')['income'].describe()\n",
    "\n",
    "print(\"Statistics for income grouped by gender:\")\n",
    "print(income_stats_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66440679-5a2f-4695-a54b-17026b5a5409",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0cdf2c64-4ea9-491d-9ca5-50cf70ec1bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics for income:\n",
      "count      59944.000000\n",
      "mean      113120.030779\n",
      "std        94828.399905\n",
      "min        20000.000000\n",
      "25%        81583.000000\n",
      "50%       101478.000000\n",
      "75%       122712.000000\n",
      "max      1000000.000000\n",
      "Name: income, dtype: float64\n",
      "Minimum income: 20000\n",
      "Maximum income: 1000000\n",
      "Mean income: 113120\n",
      "Standard deviation of income: 94828\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    INCOME STATISTICS\n",
    "'''\n",
    "\n",
    "# Calculate statistics\n",
    "income_stats = df1['income'].describe()\n",
    "\n",
    "# Additional statistics\n",
    "income_min = int(round(df1['income'].min()))\n",
    "income_max = int(round(df1['income'].max()))\n",
    "income_mean = int(round(df1['income'].mean()))\n",
    "income_std = int(round(df1['income'].std()))\n",
    "\n",
    "print(\"Basic statistics for income:\")\n",
    "print(income_stats)\n",
    "print(f\"Minimum income: {income_min}\")\n",
    "print(f\"Maximum income: {income_max}\")\n",
    "print(f\"Mean income: {income_mean}\")\n",
    "print(f\"Standard deviation of income: {income_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cede219-71d3-4e7c-ac2c-c83568944487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "edc60936-7cda-4a96-a654-12eb32807336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each status:\n",
      "status\n",
      "single            93.0\n",
      "seeing someone     3.0\n",
      "available          3.0\n",
      "married            1.0\n",
      "unknown            0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    STATUS STATISTICS\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "status_counts = df1['status'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "status_percentage= round((status_counts / len(df1)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each status:\")\n",
    "print(status_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a7a7dd3-84e9-4651-8bef-5a5811b99398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics for income grouped by status:\n",
      "                  count           mean            std      min      25%  \\\n",
      "status                                                                    \n",
      "available        1864.0  115597.020386  116452.275152  20000.0  81583.0   \n",
      "married           310.0  111846.174194   99992.173474  20000.0  81583.0   \n",
      "seeing someone   2064.0  110033.083333  112480.197993  20000.0  74556.0   \n",
      "single          55696.0  113158.426925   93267.475034  20000.0  81583.0   \n",
      "unknown            10.0  114193.500000   85512.366004  20000.0  81583.0   \n",
      "\n",
      "                     50%        75%        max  \n",
      "status                                          \n",
      "available       101478.0  129155.00  1000000.0  \n",
      "married         100000.0  129155.00  1000000.0  \n",
      "seeing someone   99588.0  110667.75  1000000.0  \n",
      "single          101478.0  122712.00  1000000.0  \n",
      "unknown         100711.0  123957.50   314571.0  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    INCOME STATISTICS BY STATUS\n",
    "'''\n",
    "\n",
    "# Group by status and calculate statistics for income\n",
    "income_stats_status = df1.groupby('status')['income'].describe()\n",
    "\n",
    "print(\"\\nStatistics for income grouped by status:\")\n",
    "print(income_stats_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6dfe38ca-0482-45a7-b299-f4fb9f01a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert  unknwonw to single which the majority for single\n",
    "df1['status'] = df1['status'].replace('unknown', 'single')\n",
    "df3=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbc926-2bc1-411d-9553-1d21e51108e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ecb276b-2e00-4ab4-911e-acbe1a4d2c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each education:\n",
      "education\n",
      "graduated from college/university    40.0\n",
      "graduated from masters program       15.0\n",
      "rather not say                       11.0\n",
      "working on college/university        10.0\n",
      "working on masters program            3.0\n",
      "graduated from two-year college       3.0\n",
      "graduated from high school            2.0\n",
      "graduated from ph.d program           2.0\n",
      "graduated from law school             2.0\n",
      "working on two-year college           2.0\n",
      "dropped out of college/university     2.0\n",
      "working on ph.d program               2.0\n",
      "college/university                    1.0\n",
      "graduated from space camp             1.0\n",
      "dropped out of space camp             1.0\n",
      "graduated from med school             1.0\n",
      "working on space camp                 1.0\n",
      "working on law school                 0.0\n",
      "two-year college                      0.0\n",
      "working on med school                 0.0\n",
      "dropped out of two-year college       0.0\n",
      "dropped out of masters program        0.0\n",
      "masters program                       0.0\n",
      "dropped out of ph.d program           0.0\n",
      "dropped out of high school            0.0\n",
      "high school                           0.0\n",
      "working on high school                0.0\n",
      "space camp                            0.0\n",
      "ph.d program                          0.0\n",
      "law school                            0.0\n",
      "dropped out of law school             0.0\n",
      "dropped out of med school             0.0\n",
      "med school                            0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    EDUCATION STATISTICS\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "education_counts = df3['education'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "education_percentage= round((education_counts / len(df3)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each education:\")\n",
    "print(education_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0b86a367-97bf-4a88-a8e7-d79a225b35e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['working on college/university', 'working on space camp',\n",
       "       'graduated from masters program',\n",
       "       'graduated from college/university', 'working on two-year college',\n",
       "       'rather not say', 'graduated from high school',\n",
       "       'working on masters program', 'graduated from space camp',\n",
       "       'college/university', 'dropped out of space camp',\n",
       "       'graduated from ph.d program', 'graduated from law school',\n",
       "       'working on ph.d program', 'two-year college',\n",
       "       'graduated from two-year college', 'working on med school',\n",
       "       'dropped out of college/university', 'space camp',\n",
       "       'graduated from med school', 'dropped out of high school',\n",
       "       'working on high school', 'masters program',\n",
       "       'dropped out of ph.d program', 'dropped out of two-year college',\n",
       "       'dropped out of med school', 'high school',\n",
       "       'working on law school', 'law school',\n",
       "       'dropped out of masters program', 'ph.d program',\n",
       "       'dropped out of law school', 'med school'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "61ddfb83-ce63-44cc-ba2d-1a70e762cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['College or more' 'Some college' 'rather not say' 'High school or less'\n",
      " 'Post graduate degree']\n"
     ]
    }
   ],
   "source": [
    "# too many values that can be grouped in 4 cats : use map function\n",
    "\n",
    "#'High school or less','Some college','College or more','Post graduate degree'\n",
    "                                   \n",
    "# Clean the 'education' column by stripping whitespace\n",
    "# Clean the 'education' column by stripping whitespace\n",
    "df3['education'] = df3['education'].str.strip()\n",
    "\n",
    "# Define the mapping dictionary\n",
    "education_mapping = {\n",
    "    ('graduated from high school', 'dropped out of high school', 'working on high school', 'high school'): 'High school or less',\n",
    "    ('working on two-year college', 'dropped out of space camp', 'two-year college', 'graduated from two-year college',\n",
    "     'dropped out of college/university', 'dropped out of two-year college', 'dropped out of med school', 'dropped out of law school'): 'Some college',\n",
    "    ('working on college/university', 'working on space camp', 'graduated from masters program', 'graduated from college/university',\n",
    "     'working on masters program', 'graduated from space camp', 'college/university', 'graduated from law school',\n",
    "     'working on ph.d program', 'space camp', 'graduated from med school', 'working on med school',\n",
    "     'masters program', 'dropped out of ph.d program', 'law school', 'dropped out of masters program',\n",
    "     'working on law school', 'med school'): 'College or more',\n",
    "    ('graduated from ph.d program', 'ph.d program'): 'Post graduate degree'\n",
    "}\n",
    "\n",
    "# Map the values using the mapping dictionary\n",
    "for key, value in education_mapping.items():\n",
    "    df3['education'] = df3['education'].replace(key, value)\n",
    "\n",
    "# Get unique values after mapping\n",
    "unique_educations_mapped = df3['education'].unique()\n",
    "\n",
    "print(unique_educations_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed2dba7d-b0f7-4223-950f-c6ea2d12eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['College or more', 'Some college', 'rather not say',\n",
       "       'High school or less', 'Post graduate degree'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b6df2c31-e1e0-47e5-89ef-f9df6706e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each education:\n",
      "education\n",
      "College or more         76.0\n",
      "rather not say          11.0\n",
      "Some college             8.0\n",
      "High school or less      3.0\n",
      "Post graduate degree     2.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    EDUCATION STATISTICS AFTER GROUPING\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "education_counts = df3['education'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "education_percentage= round((education_counts / len(df3)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each education:\")\n",
    "print(education_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc52e868-afde-4e27-85d1-ef85337069ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7a38bc8-50bd-47f4-8c93-cb279422fef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics for income grouped by education:\n",
      "                        count           mean            std      min      25%  \\\n",
      "education                                                                       \n",
      "College or more       45740.0  111315.232925   93130.105393  20000.0  81583.0   \n",
      "High school or less    1713.0   91501.667250  114261.007357  20000.0  40000.0   \n",
      "Post graduate degree   1298.0  116940.807396   87610.319342  20000.0  85366.0   \n",
      "Some college           4566.0  100285.833114  116735.644797  20000.0  50784.0   \n",
      "rather not say         6627.0  139259.353101   79202.871556  20000.0  91681.0   \n",
      "\n",
      "                           50%       75%        max  \n",
      "education                                            \n",
      "College or more       100000.0  122712.0  1000000.0  \n",
      "High school or less    81583.0  100000.0  1000000.0  \n",
      "Post graduate degree  108365.0  108924.0  1000000.0  \n",
      "Some college           81583.0  108365.0  1000000.0  \n",
      "rather not say        129155.0  185256.0  1000000.0  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    INCOME STATISTICS BY GROUP EDUCATION\n",
    "'''\n",
    "\n",
    "# Group by education and calculate statistics for income\n",
    "income_stats_education = df4.groupby('education')['income'].describe()\n",
    "\n",
    "print(\"\\nStatistics for income grouped by education:\")\n",
    "print(income_stats_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7a01a-6a94-4e90-a144-47d6f823e64c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43e1b06b-764f-4388-abca-fd3c8bc1ccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each ethnicity:\n",
      "ethnicity\n",
      "white                                                                               55.0\n",
      "asian                                                                               10.0\n",
      "rather not say                                                                       9.0\n",
      "hispanic / latin                                                                     5.0\n",
      "black                                                                                3.0\n",
      "                                                                                    ... \n",
      "asian, black, pacific islander, hispanic / latin, white                              0.0\n",
      "asian, native american, indian, pacific islander, hispanic / latin, white, other     0.0\n",
      "asian, middle eastern, black, pacific islander, hispanic / latin                     0.0\n",
      "asian, black, pacific islander, white, other                                         0.0\n",
      "asian, black, indian                                                                 0.0\n",
      "Name: count, Length: 218, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Ethnicity STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "ethnicity_counts = df4['ethnicity'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "ethnicity_percentage= round((ethnicity_counts / len(df4)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each ethnicity:\")\n",
    "print(ethnicity_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "53c79877-e5d7-4f5c-923c-92f7d87dcf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethnicity\n",
      "white                                                                               32831\n",
      "asian                                                                                6134\n",
      "rather not say                                                                       5678\n",
      "hispanic / latin                                                                     2823\n",
      "black                                                                                2008\n",
      "                                                                                    ...  \n",
      "asian, black, pacific islander, hispanic / latin, white                                 1\n",
      "asian, native american, indian, pacific islander, hispanic / latin, white, other        1\n",
      "asian, middle eastern, black, pacific islander, hispanic / latin                        1\n",
      "asian, black, pacific islander, white, other                                            1\n",
      "asian, black, indian                                                                    1\n",
      "Name: count, Length: 218, dtype: int64\n",
      "ethnicity\n",
      "white                                                                                                      32831\n",
      "asian                                                                                                       6134\n",
      "rather not say                                                                                              5678\n",
      "hispanic / latin                                                                                            2823\n",
      "black                                                                                                       2008\n",
      "other                                                                                                       1706\n",
      "hispanic / latin, white                                                                                     1301\n",
      "indian                                                                                                      1077\n",
      "asian, white                                                                                                 811\n",
      "white, other                                                                                                 641\n",
      "pacific islander                                                                                             432\n",
      "asian, pacific islander                                                                                      395\n",
      "native american, white                                                                                       338\n",
      "middle eastern                                                                                               329\n",
      "middle eastern, white                                                                                        300\n",
      "black, white                                                                                                 298\n",
      "pacific islander, white                                                                                      156\n",
      "hispanic / latin, other                                                                                      138\n",
      "black, other                                                                                                 133\n",
      "black, hispanic / latin                                                                                      119\n",
      "hispanic / latin, white, other                                                                               117\n",
      "black, native american, white                                                                                110\n",
      "black, native american                                                                                       100\n",
      "asian, other                                                                                                  95\n",
      "asian, hispanic / latin                                                                                       88\n",
      "native american, hispanic / latin, white                                                                      87\n",
      "native american, hispanic / latin                                                                             73\n",
      "asian, white, other                                                                                           69\n",
      "native american                                                                                               67\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other       66\n",
      "asian, black                                                                                                  59\n",
      "pacific islander, hispanic / latin                                                                            57\n",
      "asian, pacific islander, white                                                                                55\n",
      "native american, white, other                                                                                 54\n",
      "asian, indian                                                                                                 52\n",
      "black, white, other                                                                                           49\n",
      "indian, white                                                                                                 46\n",
      "asian, hispanic / latin, white                                                                                42\n",
      "middle eastern, white, other                                                                                  40\n",
      "middle eastern, hispanic / latin                                                                              39\n",
      "asian, pacific islander, other                                                                                38\n",
      "black, hispanic / latin, white                                                                                36\n",
      "native american, hispanic / latin, white, other                                                               33\n",
      "pacific islander, hispanic / latin, white                                                                     30\n",
      "indian, other                                                                                                 30\n",
      "black, native american, white, other                                                                          29\n",
      "black, native american, other                                                                                 27\n",
      "black, native american, hispanic / latin, white                                                               26\n",
      "middle eastern, other                                                                                         23\n",
      "black, native american, hispanic / latin                                                                      19\n",
      "pacific islander, white, other                                                                                18\n",
      "asian, native american, white                                                                                 18\n",
      "black, indian                                                                                                 17\n",
      "native american, other                                                                                        16\n",
      "asian, black, white                                                                                           15\n",
      "black, pacific islander                                                                                       15\n",
      "pacific islander, other                                                                                       14\n",
      "indian, white, other                                                                                          14\n",
      "black, hispanic / latin, other                                                                                13\n",
      "asian, pacific islander, hispanic / latin                                                                     13\n",
      "native american, hispanic / latin, other                                                                      13\n",
      "middle eastern, hispanic / latin, white                                                                       12\n",
      "indian, pacific islander                                                                                      12\n",
      "asian, middle eastern                                                                                         12\n",
      "asian, pacific islander, hispanic / latin, white                                                              11\n",
      "middle eastern, indian                                                                                        11\n",
      "asian, pacific islander, white, other                                                                         10\n",
      "black, native american, hispanic / latin, white, other                                                        10\n",
      "asian, black, native american                                                                                  9\n",
      "asian, hispanic / latin, white, other                                                                          9\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white               9\n",
      "asian, middle eastern, white                                                                                   9\n",
      "asian, hispanic / latin, other                                                                                 9\n",
      "asian, black, other                                                                                            9\n",
      "middle eastern, native american, white                                                                         8\n",
      "indian, hispanic / latin                                                                                       8\n",
      "asian, black, native american, white                                                                           8\n",
      "asian, native american, hispanic / latin, white                                                                7\n",
      "native american, pacific islander, white                                                                       7\n",
      "asian, indian, pacific islander                                                                                6\n",
      "black, indian, white                                                                                           6\n",
      "middle eastern, black                                                                                          6\n",
      "asian, black, pacific islander                                                                                 6\n",
      "asian, middle eastern, white, other                                                                            6\n",
      "native american, pacific islander, hispanic / latin                                                            5\n",
      "asian, middle eastern, indian                                                                                  5\n",
      "native american, pacific islander, hispanic / latin, white                                                     5\n",
      "pacific islander, hispanic / latin, white, other                                                               5\n",
      "asian, native american, white, other                                                                           5\n",
      "black, native american, hispanic / latin, other                                                                5\n",
      "asian, native american, hispanic / latin                                                                       5\n",
      "black, hispanic / latin, white, other                                                                          5\n",
      "asian, pacific islander, hispanic / latin, white, other                                                        5\n",
      "asian, indian, other                                                                                           5\n",
      "asian, indian, white                                                                                           5\n",
      "black, pacific islander, hispanic / latin                                                                      5\n",
      "pacific islander, hispanic / latin, other                                                                      5\n",
      "black, pacific islander, white                                                                                 4\n",
      "asian, native american, pacific islander, hispanic / latin, white                                              4\n",
      "asian, native american, hispanic / latin, white, other                                                         4\n",
      "middle eastern, indian, other                                                                                  4\n",
      "middle eastern, hispanic / latin, other                                                                        4\n",
      "black, pacific islander, other                                                                                 4\n",
      "asian, black, pacific islander, hispanic / latin                                                               4\n",
      "indian, hispanic / latin, other                                                                                4\n",
      "black, indian, white, other                                                                                    4\n",
      "asian, native american                                                                                         3\n",
      "middle eastern, native american, hispanic / latin                                                              3\n",
      "black, indian, hispanic / latin                                                                                3\n",
      "asian, indian, pacific islander, other                                                                         3\n",
      "middle eastern, pacific islander, other                                                                        3\n",
      "black, native american, indian, other                                                                          3\n",
      "native american, pacific islander, hispanic / latin, white, other                                              3\n",
      "asian, black, native american, pacific islander, white                                                         3\n",
      "asian, middle eastern, indian, other                                                                           3\n",
      "black, indian, other                                                                                           3\n",
      "asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white                      2\n",
      "asian, black, hispanic / latin                                                                                 2\n",
      "native american, pacific islander                                                                              2\n",
      "asian, middle eastern, black                                                                                   2\n",
      "asian, black, native american, hispanic / latin, white                                                         2\n",
      "asian, middle eastern, black, pacific islander, hispanic / latin, white                                        2\n",
      "asian, black, native american, white, other                                                                    2\n",
      "black, indian, hispanic / latin, white                                                                         2\n",
      "asian, native american, pacific islander, white, other                                                         2\n",
      "asian, indian, hispanic / latin                                                                                2\n",
      "asian, indian, white, other                                                                                    2\n",
      "middle eastern, hispanic / latin, white, other                                                                 2\n",
      "asian, black, hispanic / latin, other                                                                          2\n",
      "native american, pacific islander, white, other                                                                2\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other               2\n",
      "middle eastern, black, native american, white                                                                  2\n",
      "indian, hispanic / latin, white                                                                                2\n",
      "asian, native american, pacific islander, white                                                                2\n",
      "asian, native american, other                                                                                  2\n",
      "indian, hispanic / latin, white, other                                                                         2\n",
      "middle eastern, native american, hispanic / latin, white                                                       2\n",
      "asian, black, pacific islander, white                                                                          2\n",
      "asian, pacific islander, hispanic / latin, other                                                               2\n",
      "black, native american, pacific islander, white                                                                2\n",
      "asian, black, native american, pacific islander                                                                2\n",
      "middle eastern, indian, white, other                                                                           2\n",
      "black, native american, pacific islander, hispanic / latin, white                                              2\n",
      "asian, middle eastern, black, indian, pacific islander, hispanic / latin, white                                2\n",
      "asian, middle eastern, hispanic / latin, white                                                                 2\n",
      "black, native american, pacific islander, hispanic / latin, white, other                                       2\n",
      "asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other                2\n",
      "middle eastern, native american, hispanic / latin, white, other                                                2\n",
      "native american, indian                                                                                        2\n",
      "middle eastern, black, white                                                                                   2\n",
      "middle eastern, black, native american, indian, white, other                                                   2\n",
      "black, native american, pacific islander                                                                       2\n",
      "asian, black, native american, other                                                                           2\n",
      "asian, black, native american, hispanic / latin                                                                2\n",
      "asian, black, hispanic / latin, white                                                                          2\n",
      "asian, native american, pacific islander                                                                       2\n",
      "black, native american, indian, white, other                                                                   2\n",
      "asian, black, native american, pacific islander, other                                                         1\n",
      "asian, middle eastern, black, native american, indian, pacific islander, white                                 1\n",
      "asian, indian, hispanic / latin, white                                                                         1\n",
      "asian, black, native american, indian, hispanic / latin, white, other                                          1\n",
      "asian, black, indian, hispanic / latin, other                                                                  1\n",
      "asian, indian, pacific islander, hispanic / latin, white, other                                                1\n",
      "asian, middle eastern, black, native american, hispanic / latin, white                                         1\n",
      "asian, middle eastern, other                                                                                   1\n",
      "middle eastern, pacific islander                                                                               1\n",
      "middle eastern, indian, white                                                                                  1\n",
      "middle eastern, black, native american, indian, hispanic / latin, white                                        1\n",
      "middle eastern, black, native american, white, other                                                           1\n",
      "black, native american, pacific islander, other                                                                1\n",
      "middle eastern, black, pacific islander, white                                                                 1\n",
      "middle eastern, black, indian, pacific islander, hispanic / latin, white                                       1\n",
      "black, native american, indian, white                                                                          1\n",
      "asian, middle eastern, indian, hispanic / latin, white, other                                                  1\n",
      "asian, middle eastern, native american, hispanic / latin, white                                                1\n",
      "middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other               1\n",
      "asian, black, native american, indian                                                                          1\n",
      "middle eastern, black, native american, indian, pacific islander, hispanic / latin, white                      1\n",
      "middle eastern, black, hispanic / latin                                                                        1\n",
      "black, native american, pacific islander, white, other                                                         1\n",
      "black, native american, indian, hispanic / latin, white, other                                                 1\n",
      "asian, indian, hispanic / latin, other                                                                         1\n",
      "asian, black, hispanic / latin, white, other                                                                   1\n",
      "asian, native american, pacific islander, hispanic / latin, white, other                                       1\n",
      "middle eastern, native american                                                                                1\n",
      "middle eastern, black, native american, hispanic / latin, white                                                1\n",
      "black, native american, indian, pacific islander, hispanic / latin                                             1\n",
      "asian, middle eastern, black, white, other                                                                     1\n",
      "asian, middle eastern, black, pacific islander                                                                 1\n",
      "asian, black, white, other                                                                                     1\n",
      "asian, middle eastern, native american, pacific islander, hispanic / latin, white, other                       1\n",
      "native american, indian, pacific islander, hispanic / latin                                                    1\n",
      "asian, black, native american, indian, pacific islander, white                                                 1\n",
      "middle eastern, pacific islander, hispanic / latin                                                             1\n",
      "asian, black, native american, pacific islander, white, other                                                  1\n",
      "asian, middle eastern, hispanic / latin                                                                        1\n",
      "asian, black, pacific islander, other                                                                          1\n",
      "asian, native american, indian, pacific islander, hispanic / latin, white                                      1\n",
      "middle eastern, native american, white, other                                                                  1\n",
      "asian, black, native american, indian, pacific islander, hispanic / latin                                      1\n",
      "asian, middle eastern, hispanic / latin, white, other                                                          1\n",
      "middle eastern, black, native american, indian                                                                 1\n",
      "black, native american, pacific islander, hispanic / latin                                                     1\n",
      "native american, indian, white                                                                                 1\n",
      "asian, native american, hispanic / latin, other                                                                1\n",
      "black, native american, indian                                                                                 1\n",
      "asian, middle eastern, indian, hispanic / latin                                                                1\n",
      "asian, middle eastern, native american, pacific islander, other                                                1\n",
      "indian, pacific islander, hispanic / latin, white                                                              1\n",
      "asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin                      1\n",
      "asian, middle eastern, native american, pacific islander, white, other                                         1\n",
      "black, native american, indian, pacific islander                                                               1\n",
      "middle eastern, black, other                                                                                   1\n",
      "asian, black, pacific islander, hispanic / latin, white                                                        1\n",
      "asian, native american, indian, pacific islander, hispanic / latin, white, other                               1\n",
      "asian, middle eastern, black, pacific islander, hispanic / latin                                               1\n",
      "asian, black, pacific islander, white, other                                                                   1\n",
      "asian, black, indian                                                                                           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ethnicity_counts)\n",
    "# Display all rows of the ethnicity_counts\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(ethnicity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "570b7f35-b72e-4410-9dae-6bf246e92c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too many rows with weird values displaying different options in one, get just first value before the coma\n",
    "\n",
    "\n",
    "# Clean the 'ethnicity' column by splitting at commas and taking the first part\n",
    "df4['ethnicity'] = df4['ethnicity'].str.split(',').str.get(0)\n",
    "df4['ethnicity'] = df4['ethnicity'].replace('hispanic / latin', 'hispanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52a2366d-99f3-44e7-b3be-da0f6cc044ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asian', 'white', 'rather not say', 'hispanic', 'pacific islander',\n",
       "       'black', 'middle eastern', 'native american', 'indian', 'other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4['ethnicity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7731bb30-c415-4df7-8336-af1ca6aa1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pacific islander,native american' to other\n",
    "df4['ethnicity'] = df4['ethnicity'].replace('pacific islander', 'other')\n",
    "df4['ethnicity'] = df4['ethnicity'].replace('native american', 'other')\n",
    "df4['ethnicity'] = df4['ethnicity'].replace('middle eastern', 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db8d1bd0-7322-4d9d-bc4f-dfb415317f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each ethnicity:\n",
      "ethnicity\n",
      "white             56.0\n",
      "asian             14.0\n",
      "rather not say     9.0\n",
      "hispanic           7.0\n",
      "other              7.0\n",
      "black              5.0\n",
      "indian             2.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Ethnicity STATISTICS  after grouping\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "ethnicity_counts = df4['ethnicity'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "ethnicity_percentage= round((ethnicity_counts / len(df4)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each ethnicity:\")\n",
    "print(ethnicity_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e258040-1495-4219-bbc9-7381b90861dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics for income grouped by ethnicity:\n",
      "                  count           mean            std      min      25%  \\\n",
      "ethnicity                                                                 \n",
      "asian            8205.0  114525.379890   95179.119376  20000.0  81583.0   \n",
      "black            3071.0  103507.848909   97530.770965  20000.0  74556.0   \n",
      "hispanic         4379.0  108212.883763   98633.244403  20000.0  74556.0   \n",
      "indian           1196.0  118629.897993   74238.936228  20000.0  93057.0   \n",
      "other            3943.0  117261.144053  125466.150146  20000.0  81583.0   \n",
      "rather not say   5678.0  130563.674533  104193.318255  20000.0  85366.0   \n",
      "white           33472.0  110655.681405   88170.868169  20000.0  81583.0   \n",
      "\n",
      "                     50%       75%        max  \n",
      "ethnicity                                      \n",
      "asian           105455.0  122712.0  1000000.0  \n",
      "black            85366.0  115899.0  1000000.0  \n",
      "hispanic         93057.0  122712.0  1000000.0  \n",
      "indian          108365.0  129155.0  1000000.0  \n",
      "other            99588.0  129155.0  1000000.0  \n",
      "rather not say  108365.0  185256.0  1000000.0  \n",
      "white           100000.0  122712.0  1000000.0  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    INCOME STATISTICS BY ETHNICITY\n",
    "'''\n",
    "\n",
    "# Group by ethnicity and calculate statistics for income\n",
    "income_stats_ethnicity = df4.groupby('ethnicity')['income'].describe()\n",
    "\n",
    "print(\"\\nStatistics for income grouped by ethnicity:\")\n",
    "print(income_stats_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25b18def-3d6f-4f1a-bab2-0acdbf0c3ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['ethnicity'].unique()\n",
    "df5=df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2af5a-7deb-4799-9156-a52e569bb91f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c3aa1a4-da7d-4893-92a6-c6cacabf3610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categories: 49\n",
      "['gemini' 'cancer' 'pisces but it doesn&rsquo;t matter' 'pisces'\n",
      " 'aquarius' 'taurus' 'virgo' 'sagittarius'\n",
      " 'gemini but it doesn&rsquo;t matter' 'cancer but it doesn&rsquo;t matter'\n",
      " 'leo but it doesn&rsquo;t matter' 'rather not say'\n",
      " 'aquarius but it doesn&rsquo;t matter'\n",
      " 'aries and it&rsquo;s fun to think about'\n",
      " 'libra but it doesn&rsquo;t matter'\n",
      " 'pisces and it&rsquo;s fun to think about' 'libra'\n",
      " 'taurus but it doesn&rsquo;t matter'\n",
      " 'sagittarius but it doesn&rsquo;t matter' 'scorpio and it matters a lot'\n",
      " 'gemini and it&rsquo;s fun to think about'\n",
      " 'leo and it&rsquo;s fun to think about'\n",
      " 'cancer and it&rsquo;s fun to think about'\n",
      " 'libra and it&rsquo;s fun to think about'\n",
      " 'aquarius and it&rsquo;s fun to think about'\n",
      " 'virgo but it doesn&rsquo;t matter'\n",
      " 'scorpio and it&rsquo;s fun to think about'\n",
      " 'capricorn but it doesn&rsquo;t matter' 'scorpio'\n",
      " 'capricorn and it&rsquo;s fun to think about' 'leo'\n",
      " 'aries but it doesn&rsquo;t matter' 'aries'\n",
      " 'scorpio but it doesn&rsquo;t matter'\n",
      " 'sagittarius and it&rsquo;s fun to think about'\n",
      " 'libra and it matters a lot' 'taurus and it&rsquo;s fun to think about'\n",
      " 'leo and it matters a lot' 'virgo and it&rsquo;s fun to think about'\n",
      " 'cancer and it matters a lot' 'capricorn' 'pisces and it matters a lot'\n",
      " 'aries and it matters a lot' 'capricorn and it matters a lot'\n",
      " 'aquarius and it matters a lot' 'sagittarius and it matters a lot'\n",
      " 'gemini and it matters a lot' 'taurus and it matters a lot'\n",
      " 'virgo and it matters a lot']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Number of categories: ' + str(df5.sign.nunique()))\n",
    "print(df5.sign.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "841c1945-f4b1-4b62-9407-e5eb81fd1cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini' 'cancer' 'pisces' 'aquarius' 'taurus' 'virgo' 'sagittarius'\n",
      " 'leo' 'rather' 'aries' 'libra' 'scorpio' 'capricorn']\n"
     ]
    }
   ],
   "source": [
    "# there should just 12 signs - let's clean the column and extract only first word\n",
    "df5['sign'] = df5['sign'].str.split().str.get(0)\n",
    "print(df5.sign.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d389fdc7-657d-4d0b-ad6b-6ec50c6c36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rather not to say back again\n",
    "df5['sign'] = df5['sign'].replace('rather', 'rather not to say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "740da814-b180-43b8-a137-d2f4fe4e45da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each sign:\n",
      "sign\n",
      "rather not to say    18.0\n",
      "leo                   7.0\n",
      "gemini                7.0\n",
      "libra                 7.0\n",
      "cancer                7.0\n",
      "virgo                 7.0\n",
      "taurus                7.0\n",
      "scorpio               7.0\n",
      "aries                 7.0\n",
      "pisces                7.0\n",
      "sagittarius           7.0\n",
      "aquarius              7.0\n",
      "capricorn             6.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    SIGN STATISTICS\n",
    "'''\n",
    "\n",
    "sign_counts = df5['sign'].value_counts()\n",
    "\n",
    "# percentage of each value\n",
    "sign_percentage= round((sign_counts / len(df5)) * 100,0)\n",
    "\n",
    "\n",
    "print(\"Percentage of each sign:\")\n",
    "print(sign_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d7327-67dd-430e-9809-ca2c6b735b30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f937dab1-58d7-4cba-bd69-8429fef9d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each drinks:\n",
      "drinks\n",
      "socially          70.0\n",
      "rarely            10.0\n",
      "often              9.0\n",
      "not at all         5.0\n",
      "rather not say     5.0\n",
      "very often         1.0\n",
      "desperately        1.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    drinks STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "drinks_counts = df5['drinks'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "drinks_percentage= round((drinks_counts / len(df5)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each drinks:\")\n",
    "print(drinks_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce2f9b5b-ded4-4a72-bbf9-df4320b6339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change desesperately to very often\n",
    "df5['drinks'] = df5['drinks'].replace('desperately', 'very often')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "358f6db9-4c27-49eb-a603-ed1ad1d9091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks_mapping = {\n",
    "    'socially': 'sometimes',\n",
    "    'often': 'often',\n",
    "    'not at all': 'never',\n",
    "    'rarely': 'sometimes',\n",
    "    'rather not say': 'rather not say',\n",
    "    'very often': 'often'\n",
    "}\n",
    "\n",
    "# Apply mapping to 'drinks' column\n",
    "df5['drinks'] = df5['drinks'].map(drinks_mapping).fillna(df5['drinks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47c7e1d7-d4ea-4028-b251-598ba68ca61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['drinks'].unique()\n",
    "df6=df5.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2415f-2331-4e32-9cdd-1e09ea909b21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4add8297-4f94-4952-9e27-da018bd34124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each diet:\n",
      "diet\n",
      "rather not say         24394\n",
      "mostly anything        16585\n",
      "anything                6183\n",
      "strictly anything       5113\n",
      "mostly vegetarian       3444\n",
      "mostly other            1006\n",
      "strictly vegetarian      875\n",
      "vegetarian               667\n",
      "strictly other           452\n",
      "mostly vegan             338\n",
      "other                    331\n",
      "strictly vegan           228\n",
      "vegan                    136\n",
      "mostly kosher             86\n",
      "mostly halal              48\n",
      "strictly halal            18\n",
      "strictly kosher           18\n",
      "halal                     11\n",
      "kosher                    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    diet STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "diet_counts = df6['diet'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "diet_percentage= round((diet_counts / len(df6)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each diet:\")\n",
    "print(diet_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfc6d5bc-ca17-4560-abf4-41c705d9ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too many options regroup in \n",
    "\n",
    "df6['diet'] = df6['diet'].str.strip()\n",
    "\n",
    "# Mapping to consolidate values\n",
    "diet_mapping = {\n",
    "    'vegan': ['vegan', 'mostly vegan', 'strictly vegan'],\n",
    "    'vegetarian': ['vegetarian', 'mostly vegetarian', 'strictly vegetarian'],\n",
    "    'anything': ['strictly anything','mostly anything'],\n",
    "    'other':  ['mostly other', 'strictly other','other','kosher', 'mostly kosher', 'strictly kosher','halal', 'mostly halal', 'strictly halal' ]        \n",
    "}\n",
    "\n",
    "# Update values in 'diet' column based on mappings\n",
    "for new_value, old_values in diet_mapping.items():\n",
    "    for old_value in old_values:\n",
    "        df6.loc[df6['diet'].str.contains(old_value, case=False, na=False), 'diet'] = new_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0ab61a4-84e0-4ca9-9243-02db3e7a16fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anything', 'other', 'vegetarian', 'rather not say', 'vegan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['diet'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30488d3a-d898-4639-8664-a816c2b4bc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each diet:\n",
      "diet\n",
      "anything          27881\n",
      "rather not say    24394\n",
      "vegetarian         4986\n",
      "other              1981\n",
      "vegan               702\n",
      "Name: count, dtype: int64\n",
      "diet\n",
      "anything          47.0\n",
      "rather not say    41.0\n",
      "vegetarian         8.0\n",
      "other              3.0\n",
      "vegan              1.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    diet STATISTICS  after grouping\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "diet_counts = df6['diet'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "diet_percentage= round((diet_counts / len(df6)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each diet:\")\n",
    "print(diet_counts)\n",
    "print(diet_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "22be6fe8-7e7e-49de-91c4-b498f716d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df6.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28eb47-ffdb-43d9-8227-06ff28a6ece2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf59c641-1739-40ae-a45c-c212959939fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each diet:\n",
      "drugs\n",
      "never             37723\n",
      "rather not say    14079\n",
      "sometimes          7732\n",
      "often               410\n",
      "Name: count, dtype: int64\n",
      "drugs\n",
      "never             63.0\n",
      "rather not say    23.0\n",
      "sometimes         13.0\n",
      "often              1.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    drugs STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "drugs_counts = df7['drugs'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "drugs_percentage= round((drugs_counts / len(df7)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each diet:\")\n",
    "print(drugs_counts)\n",
    "print(drugs_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab2502-86f0-4295-82bd-538f07fe7923",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column smokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "058a3b12-9db9-43d6-9863-0a86f0a88104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each smoke:\n",
      "smokes\n",
      "no                43896\n",
      "rather not say     5511\n",
      "sometimes          3787\n",
      "when drinking      3039\n",
      "yes                2231\n",
      "trying to quit     1480\n",
      "Name: count, dtype: int64\n",
      "smokes\n",
      "no                73.0\n",
      "rather not say     9.0\n",
      "sometimes          6.0\n",
      "when drinking      5.0\n",
      "yes                4.0\n",
      "trying to quit     2.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    job STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "smokes_counts = df7['smokes'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "smokes_percentage= round((smokes_counts / len(df7)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each smoke:\")\n",
    "print(smokes_counts)\n",
    "print(smokes_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5081b340-0baf-417b-8904-ac11b17b3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smokes_mapping = {\n",
    "    'sometimes': 'sometimes',\n",
    "    'no': 'never',\n",
    "    'rather not say': 'rather not say',\n",
    "    'when drinking': 'sometimes',\n",
    "    'yes': 'often',\n",
    "    'trying to quit': 'sometimes'\n",
    "}\n",
    "\n",
    "# Apply mapping to 'smokes' column\n",
    "df7['smokes'] = df7['smokes'].map(smokes_mapping).fillna(df7['smokes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea030f-806e-471c-89bc-5d8bbde7930d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96645ff6-c3cc-43ee-83e9-a95be739f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each smoke:\n",
      "pets\n",
      "rather not say                     19919\n",
      "likes dogs and likes cats          14814\n",
      "likes dogs                          7224\n",
      "likes dogs and has cats             4313\n",
      "has dogs                            4134\n",
      "has dogs and likes cats             2333\n",
      "likes dogs and dislikes cats        2029\n",
      "has dogs and has cats               1474\n",
      "has cats                            1406\n",
      "likes cats                          1063\n",
      "has dogs and dislikes cats           552\n",
      "dislikes dogs and likes cats         240\n",
      "dislikes dogs and dislikes cats      196\n",
      "dislikes cats                        122\n",
      "dislikes dogs and has cats            81\n",
      "dislikes dogs                         44\n",
      "Name: count, dtype: int64\n",
      "pets\n",
      "rather not say                     33.0\n",
      "likes dogs and likes cats          25.0\n",
      "likes dogs                         12.0\n",
      "likes dogs and has cats             7.0\n",
      "has dogs                            7.0\n",
      "has dogs and likes cats             4.0\n",
      "likes dogs and dislikes cats        3.0\n",
      "has dogs and has cats               2.0\n",
      "has cats                            2.0\n",
      "likes cats                          2.0\n",
      "has dogs and dislikes cats          1.0\n",
      "dislikes dogs and likes cats        0.0\n",
      "dislikes dogs and dislikes cats     0.0\n",
      "dislikes cats                       0.0\n",
      "dislikes dogs and has cats          0.0\n",
      "dislikes dogs                       0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    pets STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "pets_counts = df7['pets'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "pets_percentage= round((pets_counts / len(df7)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each smoke:\")\n",
    "print(pets_counts)\n",
    "print(pets_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "48dc3225-29b9-4f27-8df7-2dc79cd79d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['likes dogs and likes cats', 'has cats', 'likes cats',\n",
       "       'rather not say', 'has dogs and likes cats',\n",
       "       'likes dogs and has cats', 'likes dogs and dislikes cats',\n",
       "       'has dogs', 'has dogs and dislikes cats', 'likes dogs',\n",
       "       'has dogs and has cats', 'dislikes dogs and has cats',\n",
       "       'dislikes dogs and dislikes cats', 'dislikes cats',\n",
       "       'dislikes dogs and likes cats', 'dislikes dogs'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7['pets'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2860cd48-75a3-46ec-bfd0-7c0281a57153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated values in 'pet_preference':\n",
      " ['likes both' 'likes cats' 'rather not say' 'likes dogs' 'dislikes both']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/d5x0r6t10l52bms12sy70rzc0000gn/T/ipykernel_3025/3990508507.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df7['pets'].replace(pet_mapping, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Mapping to categorize pet preferences, into 3, too many values\n",
    "pet_mapping = {\n",
    "    'likes dogs and likes cats': 'likes both',\n",
    "    'has cats': 'likes cats',\n",
    "    'likes cats': 'likes cats',\n",
    "    'rather not say': 'rather not say',\n",
    "    'has dogs and likes cats': 'likes both',\n",
    "    'likes dogs and has cats': 'likes both',\n",
    "    'likes dogs and dislikes cats': 'likes dogs',\n",
    "    'has dogs': 'likes dogs',\n",
    "    'has dogs and dislikes cats': 'likes dogs',\n",
    "    'likes dogs': 'likes dogs',\n",
    "    'has dogs and has cats': 'likes both',\n",
    "    'dislikes dogs and has cats': 'likes cats',\n",
    "    'dislikes dogs and dislikes cats': 'dislikes both',\n",
    "    'dislikes cats': 'likes dogs',\n",
    "    'dislikes dogs and likes cats': 'likes cats',\n",
    "    'dislikes dogs': 'likes cats'\n",
    "}\n",
    "\n",
    "# Update values in 'pet_preference' column based on mappings\n",
    "df7['pets'].replace(pet_mapping, inplace=True)\n",
    "\n",
    "# Display unique values in the updated 'pet_preference' column\n",
    "print(\"Updated values in 'pet_preference':\\n\", df7['pets'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "68792007-545c-4cb7-b69d-a3d2f454b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each smoke:\n",
      "pets\n",
      "likes both        22934\n",
      "rather not say    19919\n",
      "likes dogs        14061\n",
      "likes cats         2834\n",
      "dislikes both       196\n",
      "Name: count, dtype: int64\n",
      "pets\n",
      "likes both        38.0\n",
      "rather not say    33.0\n",
      "likes dogs        23.0\n",
      "likes cats         5.0\n",
      "dislikes both      0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    pets STATISTICS grouped\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "pets_counts = df7['pets'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "pets_percentage= round((pets_counts / len(df7)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each smoke:\")\n",
    "print(pets_counts)\n",
    "print(pets_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2aa5a881-2477-47e8-8dc1-aa8a1317ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=df7.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cded6e9-42d7-4f29-bbdd-7ba6f1a1bc66",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "efaca74d-84f8-415a-968b-aea63c742561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each religion:\n",
      "religion\n",
      "rather not to say    20225\n",
      "christianity         10545\n",
      "agnosticism           8812\n",
      "other                 7742\n",
      "atheism               6985\n",
      "judaism               3098\n",
      "buddhism              1948\n",
      "hinduism               450\n",
      "islam                  139\n",
      "Name: count, dtype: int64\n",
      "religion\n",
      "rather not to say    34.0\n",
      "christianity         18.0\n",
      "agnosticism          15.0\n",
      "other                13.0\n",
      "atheism              12.0\n",
      "judaism               5.0\n",
      "buddhism              3.0\n",
      "hinduism              1.0\n",
      "islam                 0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    religion STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "religion_counts = df8['religion'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "religion_percentage= round((religion_counts / len(df8)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each religion:\")\n",
    "print(religion_counts)\n",
    "print(religion_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9d69c036-5849-4593-9bd3-11a944f7e828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agnosticism' 'rather' 'atheism' 'christianity' 'other' 'buddhism'\n",
      " 'judaism' 'hinduism' 'islam']\n"
     ]
    }
   ],
   "source": [
    "# too many values, replace them with just the first word\n",
    "\n",
    "df8['religion'] = df8['religion'].str.split().str.get(0)\n",
    "\n",
    "print(df8['religion'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "703964e7-2f3d-45a8-855f-55082050bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rather not to say back again\n",
    "df8['religion'] = df8['religion'].replace('rather', 'rather not to say')\n",
    "df8['religion'] = df8['religion'].replace('catholicism', 'christianity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c759638-f613-4d70-b5ab-0a96354fe74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agnosticism' 'rather not to say' 'atheism' 'christianity' 'other'\n",
      " 'buddhism' 'judaism' 'hinduism' 'islam']\n"
     ]
    }
   ],
   "source": [
    "print(df8['religion'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4fef18a-3a64-44c6-b21c-39358cd2d047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each religion:\n",
      "religion\n",
      "rather not to say    20225\n",
      "christianity         10545\n",
      "agnosticism           8812\n",
      "other                 7742\n",
      "atheism               6985\n",
      "judaism               3098\n",
      "buddhism              1948\n",
      "hinduism               450\n",
      "islam                  139\n",
      "Name: count, dtype: int64\n",
      "religion\n",
      "rather not to say    34.0\n",
      "christianity         18.0\n",
      "agnosticism          15.0\n",
      "other                13.0\n",
      "atheism              12.0\n",
      "judaism               5.0\n",
      "buddhism              3.0\n",
      "hinduism              1.0\n",
      "islam                 0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    religion STATISTICS grouped\n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "religion_counts = df8['religion'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "religion_percentage= round((religion_counts / len(df8)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each religion:\")\n",
    "print(religion_counts)\n",
    "print(religion_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88331f4b-96ca-453f-b837-65553bc98ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=df8.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf5b47-ea6c-4cd5-8aea-6241d3fbde5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d7ba60fa-e3ae-41a3-acd2-1deec76de71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each religion:\n",
      "orientation\n",
      "straight    51604\n",
      "gay          5573\n",
      "bisexual     2767\n",
      "Name: count, dtype: int64\n",
      "orientation\n",
      "straight    86.0\n",
      "gay          9.0\n",
      "bisexual     5.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    orientation STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "orientation_counts = df9['orientation'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "orientation_percentage= round((orientation_counts / len(df9)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each religion:\")\n",
    "print(orientation_counts)\n",
    "print(orientation_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae519796-ea2f-49f1-88db-31b41e639b85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column body_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6685919c-2bb3-45a5-bc29-aef1f8a0defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each religion:\n",
      "body_type\n",
      "fit               24950\n",
      "average           14652\n",
      "skinny             6843\n",
      "curvy              6553\n",
      "rather not say     5493\n",
      "full figured       1453\n",
      "Name: count, dtype: int64\n",
      "body_type\n",
      "fit               42.0\n",
      "average           24.0\n",
      "skinny            11.0\n",
      "curvy             11.0\n",
      "rather not say     9.0\n",
      "full figured       2.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    body_type STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "body_type_counts = df9['body_type'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "body_type_percentage= round((body_type_counts / len(df9)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each religion:\")\n",
    "print(body_type_counts)\n",
    "print(body_type_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73469dc9-6519-4218-b5bd-b1117017c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#too many values lets try to put some than mean almos the same toguether\n",
    "\n",
    "# convert rather not to say back again\n",
    "df9['body_type'] = df9['body_type'].replace('thin', 'skinny')\n",
    "df9['body_type'] = df9['body_type'].replace('a little extra', 'curvy')\n",
    "df9['body_type'] = df9['body_type'].replace('overweight', 'full figured')\n",
    "df9['body_type'] = df9['body_type'].replace('jacked', 'fit')\n",
    "df9['body_type'] = df9['body_type'].replace('used up', 'skinny')\n",
    "df9['body_type'] = df9['body_type'].replace('athletic', 'fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b815a3ab-02d5-40f1-9dbe-b10592423d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['curvy', 'average', 'skinny', 'fit', 'rather not say',\n",
       "       'full figured'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9['body_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a24e05f-998d-4493-97c3-670363700ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each religion:\n",
      "body_type\n",
      "fit               24950\n",
      "average           14652\n",
      "skinny             6843\n",
      "curvy              6553\n",
      "rather not say     5493\n",
      "full figured       1453\n",
      "Name: count, dtype: int64\n",
      "body_type\n",
      "fit               42.0\n",
      "average           24.0\n",
      "skinny            11.0\n",
      "curvy             11.0\n",
      "rather not say     9.0\n",
      "full figured       2.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    body_type STATISTICS  grouped\n",
    "'''\n",
    "\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "body_type_counts = df9['body_type'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "body_type_percentage= round((body_type_counts / len(df9)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each religion:\")\n",
    "print(body_type_counts)\n",
    "print(body_type_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39e53c8e-69d0-48eb-bda5-0ecd14fecafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15=df9.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a11d91-3213-4438-a511-accd9b58cbb5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ad008220-a5b7-429a-9ef4-9b2d4f771f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75.0, 70.0, 68.0, 71.0, 66.0, 67.0, 65.0, 72.0, 62.0, 64.0, 69.0,\n",
       "       73.0, 74.0, 60.0, 63.0, 76.0, 61.0, 78.0, 79.0, 59.0, 80.0, 91.0,\n",
       "       83.0, 77.0, 58.0, 56.0, 95.0, 57.0, 87.0, 81.0, 36.0, 43.0, 52.0,\n",
       "       55.0, 53.0, 93.0, 8.0, 54.0, 82.0, 3.0, 86.0, 42.0, 84.0, 94.0,\n",
       "       50.0, 6.0, 47.0, 49.0, 48.0, '63.0', '72.0', '74.0', '69.0',\n",
       "       '71.0', '70.0', '64.0', '67.0', '68.0', '59.0', '60.0', '62.0',\n",
       "       '65.0', '73.0', '75.0', '66.0', '76.0', '61.0', '77.0', '57.0',\n",
       "       '82.0', '95.0', '78.0', '83.0', '79.0', '81.0', '94.0', '84.0',\n",
       "       '90.0', '58.0', '88.0', 'rather not say', '80.0', '37.0', '9.0',\n",
       "       '51.0', '56.0', '91.0', '36.0', '53.0', '1.0', '43.0', '92.0',\n",
       "       '26.0', '55.0', '48.0', '54.0', '85.0', '89.0', '4.0'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It says object it should be a float\n",
    "\n",
    "df15['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9fb52cb3-128b-4c1a-947c-cc7f9c3fea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows where rather not say cause they are just a few values, and to keep consistancy in terms of data type\n",
    "\n",
    "# Drop rows where 'height' is 'rather not say'\n",
    "df15 = df15[df15['height'] != 'rather not say']\n",
    "df15['height'] = df15['height'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c7c3a631-5a25-423e-8fcd-39fd83415604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75., 70., 68., 71., 66., 67., 65., 72., 62., 64., 69., 73., 74.,\n",
       "       60., 63., 76., 61., 78., 79., 59., 80., 91., 83., 77., 58., 56.,\n",
       "       95., 57., 87., 81., 36., 43., 52., 55., 53., 93.,  8., 54., 82.,\n",
       "        3., 86., 42., 84., 94., 50.,  6., 47., 49., 48., 90., 88., 37.,\n",
       "        9., 51.,  1., 92., 26., 85., 89.,  4.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ebb798-e87a-4d27-b460-f5a9b072d042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb2f14f2-49d2-430f-829a-f3d386436f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert some weird values that are missing a zero\n",
    "\n",
    "df15['height'] = df15['height'].replace(36.0, 'rather not say')\n",
    "df15['height'] = df15['height'].replace(8.0, 80.0)\n",
    "df15['height'] = df15['height'].replace(3.0, 'rather not say')\n",
    "df15['height'] = df15['height'].replace(6.0, 60.0)\n",
    "df15['height'] = df15['height'].replace(9.0, 90.0)\n",
    "df15['height'] = df15['height'].replace(1.0, 'rather not say')\n",
    "df15['height'] = df15['height'].replace(4.0, 40.0)\n",
    "df15['height'] = df15['height'].replace(0.26, 'rather not say')\n",
    "df15['height'] = df15['height'].replace(0.37, 'rather not say')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e1c620a6-d9ee-407f-a0ed-ec55e00defee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75.0, 70.0, 68.0, 71.0, 66.0, 67.0, 65.0, 72.0, 62.0, 64.0, 69.0,\n",
       "       73.0, 74.0, 60.0, 63.0, 76.0, 61.0, 78.0, 79.0, 59.0, 80.0, 91.0,\n",
       "       83.0, 77.0, 58.0, 56.0, 95.0, 57.0, 87.0, 81.0, 'rather not say',\n",
       "       43.0, 52.0, 55.0, 53.0, 93.0, 54.0, 82.0, 86.0, 42.0, 84.0, 94.0,\n",
       "       50.0, 47.0, 49.0, 48.0, 90.0, 88.0, 37.0, 51.0, 92.0, 26.0, 85.0,\n",
       "       89.0, 40.0], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce142436-987d-447e-a5bb-cd1c039d7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df15 = df15[df15['height'] != 'rather not say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c8637ac0-c0ce-4afc-92f0-8c91a6052119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75.0, 70.0, 68.0, 71.0, 66.0, 67.0, 65.0, 72.0, 62.0, 64.0, 69.0,\n",
       "       73.0, 74.0, 60.0, 63.0, 76.0, 61.0, 78.0, 79.0, 59.0, 80.0, 91.0,\n",
       "       83.0, 77.0, 58.0, 56.0, 95.0, 57.0, 87.0, 81.0, 43.0, 52.0, 55.0,\n",
       "       53.0, 93.0, 54.0, 82.0, 86.0, 42.0, 84.0, 94.0, 50.0, 47.0, 49.0,\n",
       "       48.0, 90.0, 88.0, 37.0, 51.0, 92.0, 26.0, 85.0, 89.0, 40.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8db3e0a6-cf76-4d6b-86c3-e0446b62dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16=df15.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "58f517ee-c6f7-4743-b944-3b54e20e90d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume df is your DataFrame with the 'height' column\n",
    "df16['height'] = df16['height'].apply(lambda x: (x / 100) + 1 if isinstance(x, (int, float)) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0fd5951f-35a2-4342-843d-4235bf4d75be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.75, 1.7 , 1.68, 1.71, 1.66, 1.67, 1.65, 1.72, 1.62, 1.64, 1.69,\n",
       "       1.73, 1.74, 1.6 , 1.63, 1.76, 1.61, 1.78, 1.79, 1.59, 1.8 , 1.91,\n",
       "       1.83, 1.77, 1.58, 1.56, 1.95, 1.57, 1.87, 1.81, 1.43, 1.52, 1.55,\n",
       "       1.53, 1.93, 1.54, 1.82, 1.86, 1.42, 1.84, 1.94, 1.5 , 1.47, 1.49,\n",
       "       1.48, 1.9 , 1.88, 1.37, 1.51, 1.92, 1.26, 1.85, 1.89, 1.4 ])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df16['height'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bba6bea4-9662-48d9-8ed2-e6428d66ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17=df16.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1ba206f7-2b6d-4ff7-84d6-275b68bafe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each religion:\n",
      "height\n",
      "1.70    6074\n",
      "1.68    5449\n",
      "1.67    5353\n",
      "1.72    5315\n",
      "1.69    5179\n",
      "1.71    4826\n",
      "1.66    4759\n",
      "1.64    3865\n",
      "1.65    3794\n",
      "1.73    2815\n",
      "1.63    2767\n",
      "1.74    2547\n",
      "1.62    2244\n",
      "1.75    1382\n",
      "1.61    1090\n",
      "1.60     792\n",
      "1.76     783\n",
      "1.77     280\n",
      "1.59     212\n",
      "1.78     132\n",
      "1.79      57\n",
      "1.58      53\n",
      "1.80      28\n",
      "1.95      19\n",
      "1.57      17\n",
      "1.83      12\n",
      "1.82      11\n",
      "1.81      11\n",
      "1.84       9\n",
      "1.56       8\n",
      "1.55       6\n",
      "1.53       5\n",
      "1.91       3\n",
      "1.54       3\n",
      "1.94       3\n",
      "1.50       2\n",
      "1.90       2\n",
      "1.43       2\n",
      "1.48       2\n",
      "1.88       2\n",
      "1.37       2\n",
      "1.87       1\n",
      "1.86       1\n",
      "1.93       1\n",
      "1.52       1\n",
      "1.42       1\n",
      "1.47       1\n",
      "1.49       1\n",
      "1.51       1\n",
      "1.92       1\n",
      "1.26       1\n",
      "1.85       1\n",
      "1.89       1\n",
      "1.40       1\n",
      "Name: count, dtype: int64\n",
      "height\n",
      "1.70    10.0\n",
      "1.68     9.0\n",
      "1.67     9.0\n",
      "1.72     9.0\n",
      "1.69     9.0\n",
      "1.71     8.0\n",
      "1.66     8.0\n",
      "1.64     6.0\n",
      "1.65     6.0\n",
      "1.73     5.0\n",
      "1.63     5.0\n",
      "1.74     4.0\n",
      "1.62     4.0\n",
      "1.75     2.0\n",
      "1.61     2.0\n",
      "1.60     1.0\n",
      "1.76     1.0\n",
      "1.77     0.0\n",
      "1.59     0.0\n",
      "1.78     0.0\n",
      "1.79     0.0\n",
      "1.58     0.0\n",
      "1.80     0.0\n",
      "1.95     0.0\n",
      "1.57     0.0\n",
      "1.83     0.0\n",
      "1.82     0.0\n",
      "1.81     0.0\n",
      "1.84     0.0\n",
      "1.56     0.0\n",
      "1.55     0.0\n",
      "1.53     0.0\n",
      "1.91     0.0\n",
      "1.54     0.0\n",
      "1.94     0.0\n",
      "1.50     0.0\n",
      "1.90     0.0\n",
      "1.43     0.0\n",
      "1.48     0.0\n",
      "1.88     0.0\n",
      "1.37     0.0\n",
      "1.87     0.0\n",
      "1.86     0.0\n",
      "1.93     0.0\n",
      "1.52     0.0\n",
      "1.42     0.0\n",
      "1.47     0.0\n",
      "1.49     0.0\n",
      "1.51     0.0\n",
      "1.92     0.0\n",
      "1.26     0.0\n",
      "1.85     0.0\n",
      "1.89     0.0\n",
      "1.40     0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    height STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "height_counts = df17['height'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "height_percentage= round((height_counts / len(df17)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each religion:\")\n",
    "print(height_counts)\n",
    "print(height_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da9922-8364-4c6e-9c0f-63ec691c601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fcf64-8843-44d9-9666-46e1b005897a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column speaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "68d23169-74e5-4d55-945f-38367fd7f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['english', 'english (fluently), spanish (poorly), french (poorly)',\n",
       "       'english, french, c++', ...,\n",
       "       'english (fluently), hindi (poorly), french (poorly), tamil (okay), spanish (poorly)',\n",
       "       'english (fluently), french (poorly), japanese (poorly), latin (poorly)',\n",
       "       'english (fluently), french, farsi'], dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df17['speaks'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5be46c48-7077-40f0-a615-890beeb28eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7645"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df17['speaks'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8cd81b1b-f0ec-495a-b5b6-a11d4540abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#too many values, lest just count how many languages they speak\n",
    "df17['speaks'] = df17['speaks'].str.split(',').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "647bb555-fe94-4794-8207-4adc2f891384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df17['speaks'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "91558f2f-ff40-44bc-8282-e933165b58c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each speaks:\n",
      "speaks\n",
      "1    29110\n",
      "2    17227\n",
      "3     8680\n",
      "4     3250\n",
      "5     1661\n",
      "Name: count, dtype: int64\n",
      "speaks\n",
      "1    49.0\n",
      "2    29.0\n",
      "3    14.0\n",
      "4     5.0\n",
      "5     3.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    speaks STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "speaks_counts = df17['speaks'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "speaks_percentage= round((speaks_counts / len(df17)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each speaks:\")\n",
    "print(speaks_counts)\n",
    "print(speaks_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e86185b7-a2c5-4a6a-af0b-fe3294b05f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18=df17.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f933c-5048-4462-bb83-ac8bac86d496",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0847ab82-520b-438e-af3c-a10218cb21b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df18['offspring'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8fb57c81-7739-480c-bd8c-fe45cd78790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"doesn't have kids, but might want them\", 'rather not say',\n",
       "       \"doesn't want kids\", \"doesn't have kids, but wants them\",\n",
       "       \"doesn't have kids\", 'wants kids', 'has a kid', 'has kids',\n",
       "       \"doesn't have kids, and doesn't want any\",\n",
       "       \"has kids, but doesn't want more\",\n",
       "       \"has a kid, but doesn't want more\", 'has a kid, and wants more',\n",
       "       'has kids, and might want more', 'might want kids',\n",
       "       'has a kid, and might want more', 'has kids, and wants more'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df18['offspring'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "45204bac-7586-42df-ad44-67f8e7915b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try to reduce options by mapping \n",
    "\n",
    "offspring_mapping = {\n",
    "    \"doesn't have kids, but might want them\": 'no but want',\n",
    "    'rather not say': 'rather not say',\n",
    "    \"doesn't want kids\": 'no do not want',\n",
    "    \"doesn't have kids, but wants them\": 'no but want',\n",
    "    \"doesn't have kids\": 'rather not say',\n",
    "    'wants kids': 'no but want',\n",
    "    'has a kid': 'yes',\n",
    "    'has kids': 'yes',\n",
    "    \"doesn't have kids, and doesn't want any\": 'no do not want',\n",
    "    \"has kids, but doesn't want more\": 'yes',\n",
    "    \"has a kid, but doesn't want more\": 'yes',\n",
    "    'has a kid, and wants more': 'yes',\n",
    "    'has kids, and might want more': 'yes',\n",
    "    'might want kids': 'no but want',\n",
    "    'has a kid, and might want more': 'yes',\n",
    "    'has kids, and wants more': 'yes'\n",
    "}\n",
    "\n",
    "# Update values in 'offspring' column based on mappings\n",
    "df18['offspring'] = df18['offspring'].map(offspring_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9d5fcc55-dd1a-4a55-bef3-3bee670ed7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no but want', 'rather not say', 'no do not want', 'yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df18['offspring'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "abb01706-55d6-478d-89a7-325295e295b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19=df18.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bad9a9-3c04-4e79-b884-d78f3d403f24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "02f8149a-e8b5-46bf-a96f-49e281082b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 35, 38, 23, 29, 32, 31, 24, 37, 28, 30, 39, 33, 26, 27, 20, 25,\n",
       "       40, 36, 21, 34, 43, 46, 41, 42, 45, 18, 55, 50, 59, 44, 48, 54, 51,\n",
       "       62, 52, 19, 58, 66, 53, 63, 47, 49, 61, 60, 57, 56, 65, 64, 68, 69,\n",
       "       67])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df19['age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0a78e-564c-40db-89be-6a551ecf2aa0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Change all essay column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "143282e7-a890-44ab-bc77-f26c76ebdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for column renaming\n",
    "column_mapping = {\n",
    "    'essay0': 'about_me',\n",
    "    'essay1': 'my_goals',\n",
    "    'essay2': 'my_talent',\n",
    "    'essay3': 'my_highlights',\n",
    "    'essay4': 'my_favorites',\n",
    "    'essay5': 'my_needs',\n",
    "    'essay6': 'think_about',\n",
    "    'essay7': 'typical_friday',\n",
    "    'essay8': 'my_secret',\n",
    "    'essay9': 'message_if'\n",
    "}\n",
    "\n",
    "# Rename columns using the mapping\n",
    "df19 = df19.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fabf713d-032e-44db-8a60-b5b9560ce2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 59928 entries, 0 to 59943\n",
      "Data columns (total 33 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             59928 non-null  int64  \n",
      " 1   status          59928 non-null  object \n",
      " 2   sex             59928 non-null  object \n",
      " 3   orientation     59928 non-null  object \n",
      " 4   body_type       59928 non-null  object \n",
      " 5   diet            59928 non-null  object \n",
      " 6   drinks          59928 non-null  object \n",
      " 7   drugs           59928 non-null  object \n",
      " 8   education       59928 non-null  object \n",
      " 9   ethnicity       59928 non-null  object \n",
      " 10  height          59928 non-null  float64\n",
      " 11  income          59928 non-null  int64  \n",
      " 12  job             59928 non-null  object \n",
      " 13  last_online     59928 non-null  object \n",
      " 14  location        59928 non-null  object \n",
      " 15  offspring       59928 non-null  object \n",
      " 16  pets            59928 non-null  object \n",
      " 17  religion        59928 non-null  object \n",
      " 18  sign            59928 non-null  object \n",
      " 19  smokes          59928 non-null  object \n",
      " 20  speaks          59928 non-null  int64  \n",
      " 21  about_me        59928 non-null  object \n",
      " 22  my_goals        59928 non-null  object \n",
      " 23  my_talent       59928 non-null  object \n",
      " 24  my_highlights   59928 non-null  object \n",
      " 25  my_favorites    59928 non-null  object \n",
      " 26  my_needs        59928 non-null  object \n",
      " 27  think_about     59928 non-null  object \n",
      " 28  typical_friday  59928 non-null  object \n",
      " 29  my_secret       59928 non-null  object \n",
      " 30  message_if      59928 non-null  object \n",
      " 31  city            59928 non-null  object \n",
      " 32  state           59928 non-null  object \n",
      "dtypes: float64(1), int64(3), object(29)\n",
      "memory usage: 15.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df19.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "23d54dfe-6391-4e08-8edf-36b7cc87a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20=df19.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fa2fe-6962-453d-a51d-b24199b01bd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Check how many rather not say in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83181a05-c5ed-4945-b6d9-7bd927e193d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                   0\n",
      "status                0\n",
      "sex                   0\n",
      "orientation           0\n",
      "body_type          5486\n",
      "diet              24382\n",
      "drinks             2976\n",
      "drugs             14074\n",
      "education          6619\n",
      "ethnicity          5673\n",
      "height                0\n",
      "income                0\n",
      "job                8627\n",
      "last_online           0\n",
      "location              0\n",
      "offspring         43106\n",
      "pets              19913\n",
      "religion              0\n",
      "sign                  0\n",
      "smokes             5506\n",
      "speaks                0\n",
      "about_me           5482\n",
      "my_goals           7565\n",
      "my_talent          9632\n",
      "my_highlights     11471\n",
      "my_favorites      10529\n",
      "my_needs          10842\n",
      "think_about       13765\n",
      "typical_friday    12445\n",
      "my_secret         19217\n",
      "message_if        12598\n",
      "city                  0\n",
      "state                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count 'rather not say' values in each column\n",
    "rather_not_say_counts = df20.apply(lambda x: (x == 'rather not say').sum())\n",
    "\n",
    "print(rather_not_say_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b1e29f77-b4f7-4ba4-99eb-f581b7beca58",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2127509544.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[160], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    'drugs_', 'smokes_', 'likes_dogs_', 'likes_cats_']\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#features = ['body_type_', 'education_', 'drinks_',\n",
    "           #'drugs_', 'smokes_', 'likes_dogs_', 'likes_cats_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2e9906fe-05e9-4657-84c7-8bd612abc45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows deleted: 0\n"
     ]
    }
   ],
   "source": [
    "# List of columns to check\n",
    "columns_to_check = ['body_type', 'diet', 'drinks', 'drugs', 'education', \n",
    "                    'ethnicity', 'job', 'offspring', 'pets', 'sign', 'smokes']\n",
    "\n",
    "# Identify the rows with 'rather not say' in all of the specified columns\n",
    "rows_to_delete = df20[columns_to_check].apply(lambda x: (x == 'rather not say').all(), axis=1)\n",
    "\n",
    "# Delete those rows\n",
    "df20 = df20[~rows_to_delete]\n",
    "\n",
    "# Print the number of rows deleted\n",
    "print(f\"Number of rows deleted: {rows_to_delete.sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5d8d6-159c-40fa-8b29-a8ffde448cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4c81f5fe-4820-4a99-a643-90652e09b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21=df20.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b1cacc39-bd06-46b3-a360-19a5baef05ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                   0\n",
      "status                0\n",
      "sex                   0\n",
      "orientation           0\n",
      "body_type             0\n",
      "diet              20517\n",
      "drinks             2313\n",
      "drugs             12342\n",
      "education          5681\n",
      "ethnicity          4538\n",
      "height                0\n",
      "income                0\n",
      "job                7221\n",
      "last_online           0\n",
      "location              0\n",
      "offspring         38564\n",
      "pets              17633\n",
      "religion              0\n",
      "sign                  0\n",
      "smokes             4499\n",
      "speaks                0\n",
      "about_me           4878\n",
      "my_goals           6692\n",
      "my_talent          8496\n",
      "my_highlights     10104\n",
      "my_favorites       9474\n",
      "my_needs           9604\n",
      "think_about       12270\n",
      "typical_friday    10993\n",
      "my_secret         17153\n",
      "message_if        11175\n",
      "city                  0\n",
      "state                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count 'rather not say' values in each column\n",
    "rather_not_say_counts = df21.apply(lambda x: (x == 'rather not say').sum())\n",
    "\n",
    "print(rather_not_say_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9b048d33-afd2-4f73-9977-29e53676ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'body_type' is 'rather not say'\n",
    "df21 = df21[df21['job'] != 'rather not say']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "739491f4-9c94-4431-908e-642efba24756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                   0\n",
      "status                0\n",
      "sex                   0\n",
      "orientation           0\n",
      "body_type             0\n",
      "diet              16714\n",
      "drinks             1282\n",
      "drugs             10447\n",
      "education          3152\n",
      "ethnicity          3322\n",
      "height                0\n",
      "income                0\n",
      "job                   0\n",
      "last_online           0\n",
      "location              0\n",
      "offspring         32561\n",
      "pets              13632\n",
      "religion              0\n",
      "sign                  0\n",
      "smokes             3054\n",
      "speaks                0\n",
      "about_me           3842\n",
      "my_goals           5070\n",
      "my_talent          6629\n",
      "my_highlights      7936\n",
      "my_favorites       7362\n",
      "my_needs           7509\n",
      "think_about        9731\n",
      "typical_friday     8562\n",
      "my_secret         13915\n",
      "message_if         8969\n",
      "city                  0\n",
      "state                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count 'rather not say' values in each column\n",
    "rather_not_say_counts = df21.apply(lambda x: (x == 'rather not say').sum())\n",
    "\n",
    "print(rather_not_say_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ff548470-1fa8-479c-92e1-62fb6a718562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21['status'] = df21['status'].replace('available', 'single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6fd6242e-8a73-4fc1-bf63-6c14b68294a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['single', 'seeing someone', 'married'], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df21['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "11bf1b15-9b3a-4939-afc4-a8fa9b9b221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22=df21.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0ce1f454-6447-4f70-897d-ef7613c24be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       profile_id  age  status sex orientation body_type            diet  \\\n",
      "0            1000   22  single   m    straight     curvy        anything   \n",
      "1            1001   35  single   m    straight   average           other   \n",
      "3            1002   23  single   m    straight    skinny      vegetarian   \n",
      "4            1003   29  single   m    straight       fit  rather not say   \n",
      "5            1004   29  single   m    straight   average        anything   \n",
      "...           ...  ...     ...  ..         ...       ...             ...   \n",
      "59935       48216   32  single   m    bisexual    skinny        anything   \n",
      "59940       48217   24  single   m    straight       fit        anything   \n",
      "59941       48218   42  single   m    straight   average        anything   \n",
      "59942       48219   27  single   m    straight       fit        anything   \n",
      "59943       48220   39  single   m         gay   average  rather not say   \n",
      "\n",
      "          drinks           drugs        education  ...  \\\n",
      "0      sometimes           never  College or more  ...   \n",
      "1          often       sometimes  College or more  ...   \n",
      "3      sometimes  rather not say  College or more  ...   \n",
      "4      sometimes           never  College or more  ...   \n",
      "5      sometimes  rather not say  College or more  ...   \n",
      "...          ...             ...              ...  ...   \n",
      "59935  sometimes  rather not say  College or more  ...   \n",
      "59940      often       sometimes  College or more  ...   \n",
      "59941      never           never  College or more  ...   \n",
      "59942  sometimes           often  College or more  ...   \n",
      "59943  sometimes  rather not say  College or more  ...   \n",
      "\n",
      "                                               my_talent  \\\n",
      "0      making people laugh. ranting about a good salt...   \n",
      "1      being silly. having ridiculous amonts of fun w...   \n",
      "3      playing synthesizers and organizing books acco...   \n",
      "4      creating imagery to look at: http://bagsbrown....   \n",
      "5      imagining random shit. laughing at aforementio...   \n",
      "...                                                  ...   \n",
      "59935  conscientiousness. adding -ness to words that ...   \n",
      "59940  filmmaking, photography, graphic design, web d...   \n",
      "59941  - looking at things objectively - getting thin...   \n",
      "59942                                          listening   \n",
      "59943  i'm a great bullshitter. i don't know what it ...   \n",
      "\n",
      "                                           my_highlights  \\\n",
      "0      the way i look. i am a six foot half asian, ha...   \n",
      "1                                         rather not say   \n",
      "3                      socially awkward but i do my best   \n",
      "4                i smile a lot and my inquisitive nature   \n",
      "5      i have a big smile. i also get asked if i'm we...   \n",
      "...                                                  ...   \n",
      "59935  probably that i have no hair (unless i'm weari...   \n",
      "59940                                dude, i don't know.   \n",
      "59941  i'm quiet until i get used to the environment ...   \n",
      "59942  it used to be the hair until i mowed it off bu...   \n",
      "59943  either that i am funny/sarcastic, or that i am...   \n",
      "\n",
      "                                            my_favorites  \\\n",
      "0      books: absurdistan, the republic, of mice and ...   \n",
      "1      i am die hard christopher moore fan. i don't r...   \n",
      "3      bataille, celine, beckett. . . lynch, jarmusch...   \n",
      "4      music: bands, rappers, musicians at the moment...   \n",
      "5      books: to kill a mockingbird, lord of the ring...   \n",
      "...                                                  ...   \n",
      "59935  i get anxious when people ask about favorites....   \n",
      "59940  movies: hook (the greatest adventure ever!), g...   \n",
      "59941  last book: \"game change\". movies: bourne serie...   \n",
      "59942  where to begin musically: right now i listen t...   \n",
      "59943  i just read the help by kathryn stockett, sooo...   \n",
      "\n",
      "                                                my_needs  \\\n",
      "0                      food. water. cell phone. shelter.   \n",
      "1      delicious porkness in all of its glories. my b...   \n",
      "3                                         rather not say   \n",
      "4                                         rather not say   \n",
      "5      like everyone else, i love my friends and fami...   \n",
      "...                                                  ...   \n",
      "59935  water. air. food. clothes (if its cold, though...   \n",
      "59940  iphone contact lenses headphones camera tv rem...   \n",
      "59941  - iphone - friends and family - internet - bay...   \n",
      "59942  music, family, friends, a basketball, hoop, so...   \n",
      "59943  1. family & friends & other humans - interacti...   \n",
      "\n",
      "                                             think_about  \\\n",
      "0                            duality and humorous things   \n",
      "1                                         rather not say   \n",
      "3                             cats and german philosophy   \n",
      "4                                         rather not say   \n",
      "5      what my contribution to the world is going to ...   \n",
      "...                                                  ...   \n",
      "59935                                           thinking   \n",
      "59940  i do most of my thinking on the bus to/from wo...   \n",
      "59941           aside from work, how to improve my home.   \n",
      "59942          what can i do to make someone chuckle....   \n",
      "59943  sex, myself, other people, how amazing everyth...   \n",
      "\n",
      "                                          typical_friday  \\\n",
      "0      trying to find someone to hang out with. i am ...   \n",
      "1                                         rather not say   \n",
      "3                                         rather not say   \n",
      "4                                         rather not say   \n",
      "5                                   out with my friends!   \n",
      "...                                                  ...   \n",
      "59935  was in class friday nights this past semester....   \n",
      "59940      bringin' home bacon, or drinking and shakin'!   \n",
      "59941    out enjoying friendly conversation over dinner.   \n",
      "59942  what i would do on any other day. everydays a ...   \n",
      "59943  out at happy hour with my friends, running int...   \n",
      "\n",
      "                                               my_secret  \\\n",
      "0      i am new to california and looking for someone...   \n",
      "1      i am very open and will share just about anyth...   \n",
      "3                                         rather not say   \n",
      "4                                         rather not say   \n",
      "5      i cried on my first day at school because a bi...   \n",
      "...                                                  ...   \n",
      "59935  i wish my sexual preferences were clearer to m...   \n",
      "59940  when i was 18 i got a tattoo of waldo somewher...   \n",
      "59941               please let me think about this more.   \n",
      "59942  i like walking around in other people's house ...   \n",
      "59943  i wish i could cry like holly hunter in broadc...   \n",
      "\n",
      "                                              message_if                 city  \\\n",
      "0      you want to be swept off your feet! you are ti...  south san francisco   \n",
      "1                                         rather not say              oakland   \n",
      "3                                  you feel so inclined.             berkeley   \n",
      "4                                         rather not say        san francisco   \n",
      "5                                        you're awesome.        san francisco   \n",
      "...                                                  ...                  ...   \n",
      "59935              you don't know what it's all about...        san francisco   \n",
      "59940     meh if you made it this far you might as well.        san francisco   \n",
      "59941                         we have similar interests.  south san francisco   \n",
      "59942              you are interested and interesting...        san francisco   \n",
      "59943  if you have a back-bone, an opinion, a sense o...        san francisco   \n",
      "\n",
      "            state  \n",
      "0      california  \n",
      "1      california  \n",
      "3      california  \n",
      "4      california  \n",
      "5      california  \n",
      "...           ...  \n",
      "59935  california  \n",
      "59940  california  \n",
      "59941  california  \n",
      "59942  california  \n",
      "59943  california  \n",
      "\n",
      "[47221 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "#Generate unique profile IDs starting from 1000\n",
    "df22['profile_id'] = range(1000, 1000 + len(df22))\n",
    "\n",
    "# Reorder the columns to place 'profile_id' at the beginning\n",
    "cols = ['profile_id'] + [col for col in df22 if col != 'profile_id']\n",
    "df22 = df22[cols]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2eb2745a-39f8-4b6c-bf3e-b1b4a0975c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24=df22.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80092455-60a1-44b1-932d-e2a0248264b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Column job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4caa0483-cba3-4f5b-bc51-6b37fb4de030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transportation', 'hospitality / travel', 'student',\n",
       "       'artistic / musical / writer', 'computer / hardware / software',\n",
       "       'banking / financial / real estate', 'sales / marketing / biz dev',\n",
       "       'other', 'medicine / health', 'entertainment / media',\n",
       "       'science / tech / engineering', 'executive / management',\n",
       "       'education / academia', 'clerical / administrative',\n",
       "       'construction / craftsmanship', 'political / government',\n",
       "       'law / legal services', 'unemployed', 'military', 'retired'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df24['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f8414087-cacb-4c88-832a-052e4a003496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formal norm  one posib value onli that groups all\n",
    "\n",
    "\n",
    "df24['job'] = df24['job'].replace('hospitality / travel', 'hospitality')\n",
    "df24['job'] = df24['job'].replace('artistic / musical / writer', 'arts')\n",
    "df24['job'] = df24['job'].replace('computer / hardware / software', 'it')\n",
    "df24['job'] = df24['job'].replace('banking / financial / real estate', 'finance')\n",
    "df24['job'] = df24['job'].replace('sales / marketing / biz dev', 'marketing')\n",
    "df24['job'] = df24['job'].replace('medicine / health', 'healthcare')\n",
    "df24['job'] = df24['job'].replace('entertainment / media', 'media')\n",
    "df24['job'] = df24['job'].replace('science / tech / engineering', 'science and tech')\n",
    "df24['job'] = df24['job'].replace('executive / management', 'management')\n",
    "df24['job'] = df24['job'].replace('education / academia', 'education')\n",
    "df24['job'] = df24['job'].replace('clerical / administrative', 'admin')\n",
    "df24['job'] = df24['job'].replace('construction / craftsmanship', 'construction')\n",
    "df24['job'] = df24['job'].replace('political / government', 'politics')\n",
    "df24['job'] = df24['job'].replace('law / legal services', 'legal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d7f13ec4-cf87-4a82-8b9c-79d7cb7f4d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transportation', 'hospitality', 'student', 'arts', 'it',\n",
       "       'finance', 'marketing', 'other', 'healthcare', 'media',\n",
       "       'science and tech', 'management', 'education', 'admin',\n",
       "       'construction', 'politics', 'legal', 'unemployed', 'military',\n",
       "       'retired'], dtype=object)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df24['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "63858fe5-d951-4451-ae61-f945948b5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of each job:\n",
      "job\n",
      "other               6976\n",
      "science and tech    4457\n",
      "student             4422\n",
      "it                  4298\n",
      "marketing           4083\n",
      "arts                4054\n",
      "healthcare          3420\n",
      "education           3150\n",
      "management          2275\n",
      "finance             2099\n",
      "media               2061\n",
      "hospitality         1267\n",
      "legal               1265\n",
      "construction         976\n",
      "admin                734\n",
      "politics             650\n",
      "transportation       345\n",
      "unemployed           251\n",
      "retired              241\n",
      "military             197\n",
      "Name: count, dtype: int64\n",
      "job\n",
      "other               15.0\n",
      "science and tech     9.0\n",
      "student              9.0\n",
      "it                   9.0\n",
      "marketing            9.0\n",
      "arts                 9.0\n",
      "healthcare           7.0\n",
      "education            7.0\n",
      "management           5.0\n",
      "finance              4.0\n",
      "media                4.0\n",
      "hospitality          3.0\n",
      "legal                3.0\n",
      "construction         2.0\n",
      "admin                2.0\n",
      "politics             1.0\n",
      "transportation       1.0\n",
      "unemployed           1.0\n",
      "retired              1.0\n",
      "military             0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    job STATISTICS \n",
    "'''\n",
    "\n",
    "# Count the occurrences of each unique value in the 'status' column\n",
    "job_counts = df24['job'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each value\n",
    "job_percentage= round((job_counts / len(df24)) * 100,0)\n",
    "\n",
    "# Display the result\n",
    "print(\"Percentage of each job:\")\n",
    "print(job_counts)\n",
    "print(job_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "84b4c4ce-a4b7-4943-af1b-3f9494724aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25=df24.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cbf39c-2c85-4e1f-a7ac-55d7acca4a04",
   "metadata": {},
   "source": [
    "# Delete column location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cbc0b337-c308-46ca-8603-c287b20a5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3931a82c-6cdc-4c51-b797-449497007c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25.drop(columns=['rjob'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d259073a-3679-4759-a62a-aa126bc12a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df26=df25.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "41988544-b079-4747-b780-61f20ffcbb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 47221 entries, 0 to 59943\n",
      "Data columns (total 33 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   profile_id      47221 non-null  int64  \n",
      " 1   age             47221 non-null  int64  \n",
      " 2   status          47221 non-null  object \n",
      " 3   sex             47221 non-null  object \n",
      " 4   orientation     47221 non-null  object \n",
      " 5   body_type       47221 non-null  object \n",
      " 6   diet            47221 non-null  object \n",
      " 7   drinks          47221 non-null  object \n",
      " 8   drugs           47221 non-null  object \n",
      " 9   education       47221 non-null  object \n",
      " 10  ethnicity       47221 non-null  object \n",
      " 11  height          47221 non-null  float64\n",
      " 12  income          47221 non-null  int64  \n",
      " 13  job             47221 non-null  object \n",
      " 14  last_online     47221 non-null  object \n",
      " 15  offspring       47221 non-null  object \n",
      " 16  pets            47221 non-null  object \n",
      " 17  religion        47221 non-null  object \n",
      " 18  sign            47221 non-null  object \n",
      " 19  smokes          47221 non-null  object \n",
      " 20  speaks          47221 non-null  int64  \n",
      " 21  about_me        47221 non-null  object \n",
      " 22  my_goals        47221 non-null  object \n",
      " 23  my_talent       47221 non-null  object \n",
      " 24  my_highlights   47221 non-null  object \n",
      " 25  my_favorites    47221 non-null  object \n",
      " 26  my_needs        47221 non-null  object \n",
      " 27  think_about     47221 non-null  object \n",
      " 28  typical_friday  47221 non-null  object \n",
      " 29  my_secret       47221 non-null  object \n",
      " 30  message_if      47221 non-null  object \n",
      " 31  city            47221 non-null  object \n",
      " 32  state           47221 non-null  object \n",
      "dtypes: float64(1), int64(4), object(28)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df26.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "50d97e26-37f4-4368-be33-45cbd39605ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['transportation', 'hospitality', 'student', 'arts', 'it',\n",
       "       'finance', 'marketing', 'other', 'healthcare', 'media',\n",
       "       'science and tech', 'management', 'education', 'admin',\n",
       "       'construction', 'politics', 'legal', 'unemployed', 'military',\n",
       "       'retired'], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df26['job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3161153b-e4d0-4df4-b196-4961adce2cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df27=df26.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54d0c3-a4e7-400e-b968-00fd726fff3e",
   "metadata": {},
   "source": [
    "# Export preprocessed csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ae1cf603-7faa-4db6-b42a-05be1173fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to /Users/marina/Desktop/final_project/data/cleaned/okcupid_preprocessed.csv\n"
     ]
    }
   ],
   "source": [
    "okcupid_preprocessed = df27\n",
    "\n",
    "# Specify the folder path\n",
    "folder_path = ('/Users/marina/Desktop/final_project/data/cleaned/')\n",
    "\n",
    "# Specify the file name\n",
    "file_name = 'okcupid_preprocessed.csv'\n",
    "\n",
    " #Combine the folder path and file name\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "okcupid_preprocessed.to_csv(file_path, index=False)\n",
    "\n",
    "print(f'DataFrame exported to {file_path}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb8254-5ace-411d-a50f-72cc72cbed22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvfinal",
   "language": "python",
   "name": "venvfinal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
